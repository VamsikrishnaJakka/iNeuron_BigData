1. Write an SQL query to find the second-highest salary from an "Employees" table.

SOLUTION: 

SELECT MAX(salary) AS second_highest_salary
FROM Employees
WHERE salary < (SELECT MAX(salary) FROM Employees);

2. Write a MapReduce program to calculate the word count of a given input text file.

SOLUTION:

from mrjob.job import MRJob
import re

class WordCount(MRJob):
    
    def mapper(self, _, line):
        # Split the line into words
        words = re.findall(r'\w+', line.lower())
        
        # Emit each word with a count of 1
        for word in words:
            yield (word, 1)
    
    def reducer(self, word, counts):
        # Sum up the counts for each word
        yield (word, sum(counts))
    
    def combiner(self, word, counts):
        # Combiner function for local aggregation
        yield (word, sum(counts))
    
if __name__ == '__main__':
    WordCount.run()

python word_count.py inputfile.txt > output.txt


3. Write a Spark program to count the number of occurrences of each word in a given text file.

SOLUTION:

from pyspark.sql import SparkSession
from pyspark.sql.functions import split, explode

# Create a Spark session
spark = SparkSession.builder.appName("WordCount").getOrCreate()

# Read the text file into a DataFrame
lines = spark.read.text("inputfile.txt").selectExpr("value as line")

# Split each line into words
words = lines.select(explode(split(lines.line, "\\s+")).alias("word"))

# Count the occurrences of each word
word_counts = words.groupBy("word").count()

# Display the word counts
word_counts.show()
